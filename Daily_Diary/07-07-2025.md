# Date: 07-07-2025

## Objectives

- Discuss and finalize backend data modeling improvements for the Reddit dashboard.
- Plan restructuring of existing **Posts**, **Comments**, and **Replies** collections into a **single consolidated collection** for better memory efficiency and easier data aggregation.
- Understand the concept and implementation strategy for a **Word Cloud collection**.
- Plan the logic for generating word clouds based on combined subreddit data (post, reply, and comment texts) using **TF-IDF weighting**.
- Document backend schema adjustments and data fetching optimizations.

## Activities Performed

- Met with the project mentor and reviewed the current collection structure.
- Learned that maintaining separate collections for **posts**, **comments**, and **replies** is inefficient and can be replaced by a **unified collection** containing all content types with a common schema.
- Drafted the new unified MongoDB collection design, identifying key fields to track post/reply/comment types within a single collection.
- Planned backend API restructuring to accommodate the new data model without breaking existing frontend integrations.
- Studied and documented the **TF-IDF (Term Frequency-Inverse Document Frequency)** technique for ranking important words in subreddit text data.
- Outlined a plan to implement a **Word Cloud collection**:
  - Combine all text content (from posts, comments, and replies) for each subreddit.
  - Extract the top **50/100/200 words** per subreddit.
  - Apply **TF-IDF weighting** to score and rank words by relevance.
  - Store the results in a new **WordCloud collection** for efficient frontend retrieval.
- Discussed how this Word Cloud data can be visualized using a suitable **Word Cloud graph component** on the dashboard.

## Challenges Faced

- Restructuring backend data models without breaking existing API routes requires careful planning.
- Ensuring backward compatibility for currently integrated frontend components while migrating to a single collection.
- Conceptually understanding the TF-IDF scoring mechanism and how to preprocess, clean, and tokenize subreddit text data efficiently.
- Mapping out how to dynamically generate and store word cloud data per subreddit while handling large text datasets and stop words.

## Learnings

- Understood the trade-offs between multiple collections vs a unified collection in MongoDB and how merging them can reduce memory overhead and simplify querying.
- Gained conceptual clarity on **TF-IDF** as a technique to measure word importance relative to a collection of documents.
- Learned about designing backend data processing pipelines for generating derived data collections (like WordClouds) based on existing content.
- Realized the importance of backend scalability planning early in dashboard projects to avoid technical debt.

## Next Steps

- Implement the new unified MongoDB **Posts-Comments-Replies collection** structure.
- Update all backend APIs to work with the unified collection and test existing frontend components for compatibility.
- Start building the **Word Cloud generator module**:
  - Write scripts to preprocess subreddit text data.
  - Apply TF-IDF weighting.
  - Store top-ranked words in the **WordCloud collection**.
- Integrate a Word Cloud visualization component in the frontend dashboard.
- Add basic loading, error, and empty state handling for the Word Cloud component.
- Expand dummy and real data to test the full dashboard pipeline with the new architecture.

## References

- [Conditional Rendering in React](https://react.dev/learn/conditional-rendering)
- [Recharts Documentation](https://recharts.org/en-US/)
- Fellow internâ€™s JSON sample data for posts, comments, and replies.

