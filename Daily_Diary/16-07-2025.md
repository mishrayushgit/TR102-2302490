# Date: 16-07-2025  

## Objectives  

- Understand core concepts behind emotion detection before writing the processing code.
- Prepare to store emotion classification results into a new MongoDB collection: `text_emotion_collection`.

## Activities Performed  

- Read and understood foundational topics related to emotion classification on text data using pretrained models:
  - What pretrained AI models are and how they help avoid training from scratch.
  - Overview of **RoBERTa**, a transformer-based model designed for language understanding tasks.
  - Concept of tokens and subword tokenization used to process input text into model-understandable format.
  - Introduction to **sequence classification** — assigning a label (like an emotion) to an input sequence.
  - What tensors are and how they're structured in deep learning workflows.
  - Basics of **forward pass** and **logits** — understanding how a model produces output predictions.
  - Refreshed knowledge of **NumPy arrays**, often used in handling intermediate tensor and numerical data in Python.

## Challenges Faced  

- Needed time to connect all concepts together — from tokenizing input to interpreting model output in real-world inference.

## Learnings  

- Developed a clearer understanding of how pretrained transformer models like RoBERTa are used for emotion detection.
- Understood the role of tokenization, tensors, and forward propagation in the emotion classification pipeline.
- Gained confidence to start coding the emotion detection and storage logic.

## Next Steps  

- Begin writing the script that:
  - Loads the pretrained emotion detection model.
  - Applies it to all text entries in the database.
  - Stores the predicted emotion in the `text_emotion_collection`.
- Meet with professor to show progress and receive further instructions.
- Test script performance and optimize batch processing if needed.

## References  

- [What is a Pretrained AI Model?](https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/)  
- [Overview of RoBERTa Model](https://www.geeksforgeeks.org/machine-learning/overview-of-roberta-model/)  
- [What are Tokens](https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037)  
- [Sequence Classification](https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037)  
- [What Are Tensors](https://www.geeksforgeeks.org/deep-learning/what-is-tensor-and-tensor-shapes/)  
- [Forward Propagation and Logits](https://www.geeksforgeeks.org/deep-learning/what-is-forward-propagation-in-neural-networks/)  
- [Basics of NumPy Arrays](https://www.geeksforgeeks.org/python/basics-of-numpy-arrays/)
